{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AI-BagCounter: Demo & Analysis\n",
                "\n",
                "This notebook provides a walkthrough of the bag counting system, demonstrating detection, tracking, and the line-crossing logic."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "from ultralytics import YOLO\n",
                "import os\n",
                "\n",
                "# Sample Video Paths\n",
                "s1_path = '../Problem_Statement_Scenario1.mp4'\n",
                "s2_path = '../Problem_Statement_Scenario2.mp4'\n",
                "s3_path = '../Problem_Statement_Scenario3.mp4'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Frame Extraction\n",
                "Let's look at a sample frame from Scenario 1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_sample_frame(video_path):\n",
                "    if not os.path.exists(video_path):\n",
                "        print(f\"File not found: {video_path}\")\n",
                "        return\n",
                "    cap = cv2.VideoCapture(video_path)\n",
                "    ret, frame = cap.read()\n",
                "    cap.release()\n",
                "    if ret:\n",
                "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
                "        plt.figure(figsize=(10, 6))\n",
                "        plt.imshow(frame_rgb)\n",
                "        plt.title(f\"Sample Frame: {os.path.basename(video_path)}\")\n",
                "        plt.axis('off')\n",
                "        plt.show()\n",
                "    else:\n",
                "        print(\"Could not read frame\")\n",
                "\n",
                "show_sample_frame(s1_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. YOLOv8 Detection Demo\n",
                "Running a single detection pass on the sample frame."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = YOLO('yolov8n.pt')\n",
                "img = cv2.imread('sample_frame.jpg') # Assuming we saved it earlier or just use a frame\n",
                "\n",
                "# Note: In actual run, we process the frame from the video capture\n",
                "results = model.predict(s1_path, save=False, frames=1, conf=0.4)\n",
                "res_plotted = results[0].plot()\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.imshow(cv2.cvtColor(res_plotted, cv2.COLOR_BGR2RGB))\n",
                "plt.title(\"YOLOv8 Detection Output\")\n",
                "plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Counting Line Visualization\n",
                "The virtual line is used to trigger count increments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_line_overlay(video_path, line_pos=0.5):\n",
                "    if not os.path.exists(video_path):\n",
                "        return\n",
                "    cap = cv2.VideoCapture(video_path)\n",
                "    ret, frame = cap.read()\n",
                "    cap.release()\n",
                "    if ret:\n",
                "        h, w = frame.shape[:2]\n",
                "        line_x = int(w * line_pos)\n",
                "        cv2.line(frame, (line_x, 0), (line_x, h), (0, 0, 255), 5)\n",
                "        plt.figure(figsize=(10, 6))\n",
                "        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
                "        plt.title(f\"Counting Line at {line_pos*100}%\")\n",
                "        plt.axis('off')\n",
                "        plt.show()\n",
                "\n",
                "show_line_overlay(s1_path, 0.4)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Final Count Comparison\n",
                "Hypothetical results based on scenario tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scenarios = ['Scenario 1', 'Scenario 2', 'Scenario 3']\n",
                "counts = [12, 8, 15] # Mock counts for illustration\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "plt.bar(scenarios, counts, color=['skyblue', 'salmon', 'lightgreen'])\n",
                "plt.xlabel('Scenario')\n",
                "plt.ylabel('Bag Count')\n",
                "plt.title('Bag Count Comparison Across Scenarios')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}